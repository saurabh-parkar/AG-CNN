{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.measure import label\n",
    "from model import Densenet121_AG, Fusion_Branch\n",
    "from PIL import Image\n",
    "\n",
    "#np.set_printoptions(threshold = np.nan)\n",
    "\n",
    "\n",
    "CKPT_PATH = ''\n",
    "\n",
    "CKPT_PATH_G = '/best_model/AG_CNN_Global_epoch_1.pkl' \n",
    "CKPT_PATH_L = '/best_model/AG_CNN_Local_epoch_2.pkl' \n",
    "CKPT_PATH_F = '/best_model/AG_CNN_Fusion_epoch_23.pkl'\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "DATA_DIR = '/scratch/parkar.s/NIH/images'\n",
    "TRAIN_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/train_list.txt'\n",
    "VAL_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/val_list.txt'\n",
    "TEST_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/test_list.txt'\n",
    "\n",
    "num_epochs = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n",
    "\n",
    "\n",
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # fm => mask =>(+ ori-img) => crop = patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda\n",
    "\n",
    "\n",
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "       lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc \n",
    "\n",
    "\n",
    "def main():\n",
    "    print('********************load data********************')\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalize,\n",
    "                                    ]))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=128,\n",
    "                             shuffle=False, num_workers=4, pin_memory=True)\n",
    "    print('********************load data succeed!********************')\n",
    "\n",
    "\n",
    "    print('********************load model********************')\n",
    "    # initialize and load the model\n",
    "    Global_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Local_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Fusion_Branch_model = Fusion_Branch(input_size = 2048, output_size = N_CLASSES).cuda()\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_G):\n",
    "        checkpoint = torch.load(CKPT_PATH_G)\n",
    "        Global_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Global_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_L):\n",
    "        checkpoint = torch.load(CKPT_PATH_L)\n",
    "        Local_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Local_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_F):\n",
    "        checkpoint = torch.load(CKPT_PATH_F)\n",
    "        Fusion_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Fusion_Branch_model checkpoint\")\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    print('******************** load model succeed!********************')\n",
    "\n",
    "    print('******* begin testing!*********')\n",
    "    test(Global_Branch_model, Local_Branch_model, Fusion_Branch_model,test_loader)\n",
    "\n",
    "def test(model_global, model_local, model_fusion, test_loader):\n",
    "    df = pd.DataFrame(columns=['global', 'local', 'fusion'])\n",
    "    # initialize the ground truth and output tensor\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred_global = torch.FloatTensor().cuda()\n",
    "    pred_local = torch.FloatTensor().cuda()\n",
    "    pred_fusion = torch.FloatTensor().cuda()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model_global.eval()\n",
    "    model_local.eval()\n",
    "    model_fusion.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    for i, (inp, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            if i % 2000 == 0:\n",
    "                print('testing process:',i)\n",
    "            target = target.cuda()\n",
    "            gt = torch.cat((gt, target), 0)\n",
    "            input_var = torch.autograd.Variable(inp.cuda())\n",
    "            #output = model_global(input_var)\n",
    "\n",
    "            output_global, fm_global, pool_global = model_global(input_var)\n",
    "            \n",
    "            patchs_var = Attention_gen_patchs(inp,fm_global)\n",
    "\n",
    "            output_local, _, pool_local = model_local(patchs_var)\n",
    "\n",
    "            output_fusion = model_fusion(pool_global,pool_local)\n",
    "\n",
    "            pred_global = torch.cat((pred_global, output_global.data), 0)\n",
    "            pred_local = torch.cat((pred_local, output_local.data), 0)\n",
    "            pred_fusion = torch.cat((pred_fusion, output_fusion.data), 0)\n",
    "            \n",
    "            df = df.append({\n",
    "                             \"global\": pred_global.cpu().numpy(),\n",
    "                             \"local\":  pred_local.cpu().numpy(),\n",
    "                             \"fusion\": pred_fusion.cpu().numpy()\n",
    "                              }, ignore_index=True)\n",
    "            \n",
    "    df.to_csv(\"results.csv\")\n",
    "    AUROCs_g = compute_AUCs(gt, pred_global)\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "\n",
    "    AUROCs_l = compute_AUCs(gt, pred_local)\n",
    "    AUROC_avg = np.array(AUROCs_l).mean()\n",
    "    print('\\n')\n",
    "    print('Local branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "    AUROCs_f = compute_AUCs(gt, pred_fusion)\n",
    "    AUROC_avg = np.array(AUROCs_f).mean()\n",
    "    print('\\n')\n",
    "    print('Fusion branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_f[i]))\n",
    "\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/')\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.measure import label\n",
    "from model import Densenet121_AG, Fusion_Branch\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CKPT_PATH = ''\n",
    "\n",
    "CKPT_PATH_G = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/best_model/AG_CNN_Global_epoch_1.pkl' \n",
    "CKPT_PATH_L = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/best_model/AG_CNN_Local_epoch_2.pkl' \n",
    "CKPT_PATH_F = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/best_model/AG_CNN_Fusion_epoch_23.pkl'\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "DATA_DIR = '/scratch/parkar.s/NIH/images'\n",
    "TRAIN_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/train_list.txt'\n",
    "VAL_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/val_list.txt'\n",
    "TEST_IMAGE_LIST = '/home/parkar.s/NIH_multilabel_classification/AG-CNN-master/labels/test_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # fm => mask =>(+ ori-img) => crop = patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda\n",
    "\n",
    "\n",
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "       lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('********************load data********************')\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalize,\n",
    "                                    ]))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=128,\n",
    "                             shuffle=False, num_workers=4, pin_memory=True)\n",
    "    print('********************load data succeed!********************')\n",
    "\n",
    "\n",
    "    print('********************load model********************')\n",
    "    # initialize and load the model\n",
    "    Global_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Local_Branch_model = Densenet121_AG(pretrained = False, num_classes = N_CLASSES).cuda()\n",
    "    Fusion_Branch_model = Fusion_Branch(input_size = 2048, output_size = N_CLASSES).cuda()\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_G):\n",
    "        checkpoint = torch.load(CKPT_PATH_G)\n",
    "        Global_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Global_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_L):\n",
    "        checkpoint = torch.load(CKPT_PATH_L)\n",
    "        Local_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Local_Branch_model checkpoint\")\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH_F):\n",
    "        checkpoint = torch.load(CKPT_PATH_F)\n",
    "        Fusion_Branch_model.load_state_dict(checkpoint)\n",
    "        print(\"=> loaded Fusion_Branch_model checkpoint\")\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    print('******************** load model succeed!********************')\n",
    "\n",
    "    print('******* begin testing!*********')\n",
    "    test(Global_Branch_model, Local_Branch_model, Fusion_Branch_model,test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_global, model_local, model_fusion, test_loader):\n",
    "    # initialize the ground truth and output tensor\n",
    "    gt = torch.FloatTensor().cuda()\n",
    "    pred_global = torch.FloatTensor().cuda()\n",
    "    pred_local = torch.FloatTensor().cuda()\n",
    "    pred_fusion = torch.FloatTensor().cuda()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model_global.eval()\n",
    "    model_local.eval()\n",
    "    model_fusion.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    for i, (inp, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            if i % 2000 == 0:\n",
    "                print('testing process:',i)\n",
    "            target = target.cuda()\n",
    "            gt = torch.cat((gt, target), 0)\n",
    "            input_var = torch.autograd.Variable(inp.cuda())\n",
    "            #output = model_global(input_var)\n",
    "\n",
    "            output_global, fm_global, pool_global = model_global(input_var)\n",
    "            \n",
    "            patchs_var = Attention_gen_patchs(inp,fm_global)\n",
    "\n",
    "            output_local, _, pool_local = model_local(patchs_var)\n",
    "\n",
    "            output_fusion = model_fusion(pool_global,pool_local)\n",
    "\n",
    "            pred_global = torch.cat((pred_global, output_global.data), 0)\n",
    "            pred_local = torch.cat((pred_local, output_local.data), 0)\n",
    "            pred_fusion = torch.cat((pred_fusion, output_fusion.data), 0)\n",
    "\n",
    "    AUROCs_g = compute_AUCs(gt, pred_global)\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "\n",
    "    AUROCs_l = compute_AUCs(gt, pred_local)\n",
    "    AUROC_avg = np.array(AUROCs_l).mean()\n",
    "    print('\\n')\n",
    "    print('Local branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "    AUROCs_f = compute_AUCs(gt, pred_fusion)\n",
    "    AUROC_avg = np.array(AUROCs_f).mean()\n",
    "    print('\\n')\n",
    "    print('Fusion branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_f[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************load data********************\n",
      "********************load data succeed!********************\n",
      "********************load model********************\n",
      "=> loaded Global_Branch_model checkpoint\n",
      "=> loaded Local_Branch_model checkpoint\n",
      "=> loaded Fusion_Branch_model checkpoint\n",
      "******************** load model succeed!********************\n",
      "******* begin testing!*********\n",
      "testing process: 0\n",
      "Global branch: The average AUROC is 0.839\n",
      "The AUROC of Atelectasis is 0.8235533886444886\n",
      "The AUROC of Cardiomegaly is 0.9149241952800922\n",
      "The AUROC of Effusion is 0.8855035354476384\n",
      "The AUROC of Infiltration is 0.7073807025933601\n",
      "The AUROC of Mass is 0.842885687173941\n",
      "The AUROC of Nodule is 0.7757691500658777\n",
      "The AUROC of Pneumonia is 0.7767529908446988\n",
      "The AUROC of Pneumothorax is 0.8680464347715948\n",
      "The AUROC of Consolidation is 0.812716068268377\n",
      "The AUROC of Edema is 0.893131436752413\n",
      "The AUROC of Emphysema is 0.9152570820648865\n",
      "The AUROC of Fibrosis is 0.8239411807849655\n",
      "The AUROC of Pleural_Thickening is 0.7841429488645304\n",
      "The AUROC of Hernia is 0.9223135996393109\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.793\n",
      "The AUROC of Atelectasis is 0.7885733364222347\n",
      "The AUROC of Cardiomegaly is 0.8877437018381757\n",
      "The AUROC of Effusion is 0.858908022785312\n",
      "The AUROC of Infiltration is 0.6849889425593866\n",
      "The AUROC of Mass is 0.7936913093743395\n",
      "The AUROC of Nodule is 0.6992027041276611\n",
      "The AUROC of Pneumonia is 0.7195223028023795\n",
      "The AUROC of Pneumothorax is 0.8259605132007\n",
      "The AUROC of Consolidation is 0.7885189036562503\n",
      "The AUROC of Edema is 0.8655581102805506\n",
      "The AUROC of Emphysema is 0.8399517945365111\n",
      "The AUROC of Fibrosis is 0.7559534761121253\n",
      "The AUROC of Pleural_Thickening is 0.7438801346085965\n",
      "The AUROC of Hernia is 0.8491427252871583\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.838\n",
      "The AUROC of Atelectasis is 0.8245042788303306\n",
      "The AUROC of Cardiomegaly is 0.9168672991603081\n",
      "The AUROC of Effusion is 0.8857761203112423\n",
      "The AUROC of Infiltration is 0.7068134209470913\n",
      "The AUROC of Mass is 0.8445553373195926\n",
      "The AUROC of Nodule is 0.7730574955540098\n",
      "The AUROC of Pneumonia is 0.7671726606460589\n",
      "The AUROC of Pneumothorax is 0.8670750282572212\n",
      "The AUROC of Consolidation is 0.8117036382670514\n",
      "The AUROC of Edema is 0.891719117333351\n",
      "The AUROC of Emphysema is 0.9141581795873509\n",
      "The AUROC of Fibrosis is 0.8230490323669143\n",
      "The AUROC of Pleural_Thickening is 0.7850024605912979\n",
      "The AUROC of Hernia is 0.9232886937991667\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
